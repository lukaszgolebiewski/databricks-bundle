 clusters:
    personal-compute:
      name: "lukasz1_${bundle.environment}"
      spark_version: "13.3.x-scala2.12"  # Choose latest LTS version
      node_type_id: "Standard_D3_v2"      # Smallest possible (change based on region pricing)
      autoscale:
        min_workers: 1
        max_workers: 1
      data_security_mode: "NONE"
      policy_id: ""  # No restrictive policy applied
      spark_conf:
        spark.databricks.cluster.profile: "singleNode"  # Forces smallest compute
      custom_tags:
        Purpose: "Personal Compute - Cheapest"